#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹ç®¡ç†å™¨ - Unlimited Agent
è´Ÿè´£æ¨¡å‹çš„ä¸‹è½½ã€åŠ è½½å’Œç®¡ç†
"""

import os
import json
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

try:
    from huggingface_hub import hf_hub_download, list_repo_files
    from rich.console import Console
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn
    from rich.table import Table
    from rich.panel import Panel
except ImportError as e:
    print(f"ç¼ºå°‘ä¾èµ–åº“: {e}")
    raise

from config import Config

@dataclass
class ModelInfo:
    """æ¨¡å‹ä¿¡æ¯æ•°æ®ç±»"""
    name: str
    repo_id: str
    filename: str
    description: str
    size: str
    local_path: Optional[str] = None
    is_downloaded: bool = False
    checksum: Optional[str] = None

class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨ç±»"""
    
    def __init__(self, models_dir: str = "./models"):
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(exist_ok=True)
        self.console = Console()
        self.model_registry_file = self.models_dir / "model_registry.json"
        self.model_registry = self._load_model_registry()
    
    def _load_model_registry(self) -> Dict:
        """åŠ è½½æ¨¡å‹æ³¨å†Œè¡¨"""
        if self.model_registry_file.exists():
            try:
                with open(self.model_registry_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                self.console.print(f"[yellow]è­¦å‘Š: æ— æ³•åŠ è½½æ¨¡å‹æ³¨å†Œè¡¨: {e}[/yellow]")
        return {}
    
    def _save_model_registry(self):
        """ä¿å­˜æ¨¡å‹æ³¨å†Œè¡¨"""
        try:
            with open(self.model_registry_file, 'w', encoding='utf-8') as f:
                json.dump(self.model_registry, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.console.print(f"[red]é”™è¯¯: æ— æ³•ä¿å­˜æ¨¡å‹æ³¨å†Œè¡¨: {e}[/red]")
    
    def _calculate_file_checksum(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œ"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception:
            return ""
    
    def list_available_models(self) -> List[ModelInfo]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        models = []
        for model_config in Config.get_all_models():
            model_info = ModelInfo(
                name=model_config['name'],
                repo_id=model_config['repo_id'],
                filename=model_config['filename'],
                description=model_config['description'],
                size=model_config['size']
            )
            
            # æ£€æŸ¥æ˜¯å¦å·²ä¸‹è½½
            local_path = self.models_dir / model_config['filename']
            if local_path.exists():
                model_info.local_path = str(local_path)
                model_info.is_downloaded = True
                model_info.checksum = self._calculate_file_checksum(local_path)
            
            models.append(model_info)
        
        return models
    
    def display_models_table(self):
        """æ˜¾ç¤ºæ¨¡å‹è¡¨æ ¼"""
        models = self.list_available_models()
        
        table = Table(title="ğŸ¤– å¯ç”¨æ¨¡å‹åˆ—è¡¨")
        table.add_column("åç§°", style="cyan", no_wrap=True)
        table.add_column("æè¿°", style="white")
        table.add_column("å¤§å°", style="yellow")
        table.add_column("çŠ¶æ€", style="green")
        table.add_column("æ¨è", style="magenta")
        
        for model in models:
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ¨èæ¨¡å‹
            is_recommended = any(
                m['name'] == model.name and m.get('recommended', False) 
                for m in Config.get_all_models()
            )
            
            status = "âœ… å·²ä¸‹è½½" if model.is_downloaded else "â¬‡ï¸ æœªä¸‹è½½"
            recommended = "â­" if is_recommended else ""
            
            table.add_row(
                model.name,
                model.description,
                model.size,
                status,
                recommended
            )
        
        self.console.print(table)
    
    def download_model(self, model_name: str, force_redownload: bool = False) -> Optional[str]:
        """ä¸‹è½½æŒ‡å®šæ¨¡å‹"""
        # æŸ¥æ‰¾æ¨¡å‹é…ç½®
        model_config = None
        for config in Config.get_all_models():
            if config['name'] == model_name:
                model_config = config
                break
        
        if not model_config:
            self.console.print(f"[red]é”™è¯¯: æœªæ‰¾åˆ°æ¨¡å‹ '{model_name}'[/red]")
            return None
        
        local_path = self.models_dir / model_config['filename']
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ä¸”ä¸å¼ºåˆ¶é‡æ–°ä¸‹è½½
        if local_path.exists() and not force_redownload:
            self.console.print(f"[green]æ¨¡å‹ '{model_name}' å·²å­˜åœ¨: {local_path}[/green]")
            return str(local_path)
        
        try:
            self.console.print(f"[yellow]å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}[/yellow]")
            self.console.print(f"[cyan]ä»“åº“: {model_config['repo_id']}[/cyan]")
            self.console.print(f"[cyan]æ–‡ä»¶: {model_config['filename']}[/cyan]")
            
            # ä½¿ç”¨è¿›åº¦æ¡ä¸‹è½½
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                TaskProgressColumn(),
                console=self.console
            ) as progress:
                task = progress.add_task(f"ä¸‹è½½ {model_name}...", total=None)
                
                # ä¸‹è½½æ¨¡å‹
                downloaded_path = hf_hub_download(
                    repo_id=model_config['repo_id'],
                    filename=model_config['filename'],
                    cache_dir=str(self.models_dir),
                    local_dir=str(self.models_dir),
                    local_dir_use_symlinks=False
                )
                
                progress.update(task, completed=True)
            
            # æ›´æ–°æ¨¡å‹æ³¨å†Œè¡¨
            self.model_registry[model_name] = {
                'repo_id': model_config['repo_id'],
                'filename': model_config['filename'],
                'local_path': downloaded_path,
                'checksum': self._calculate_file_checksum(Path(downloaded_path)),
                'download_time': str(Path(downloaded_path).stat().st_mtime)
            }
            self._save_model_registry()
            
            self.console.print(f"[green]âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {downloaded_path}[/green]")
            return downloaded_path
            
        except Exception as e:
            self.console.print(f"[red]âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}[/red]")
            return None
    
    def delete_model(self, model_name: str) -> bool:
        """åˆ é™¤æŒ‡å®šæ¨¡å‹"""
        model_config = None
        for config in Config.get_all_models():
            if config['name'] == model_name:
                model_config = config
                break
        
        if not model_config:
            self.console.print(f"[red]é”™è¯¯: æœªæ‰¾åˆ°æ¨¡å‹ '{model_name}'[/red]")
            return False
        
        local_path = self.models_dir / model_config['filename']
        
        if not local_path.exists():
            self.console.print(f"[yellow]æ¨¡å‹ '{model_name}' æœªä¸‹è½½ï¼Œæ— éœ€åˆ é™¤[/yellow]")
            return True
        
        try:
            local_path.unlink()
            
            # ä»æ³¨å†Œè¡¨ä¸­ç§»é™¤
            if model_name in self.model_registry:
                del self.model_registry[model_name]
                self._save_model_registry()
            
            self.console.print(f"[green]âœ… æ¨¡å‹ '{model_name}' å·²åˆ é™¤[/green]")
            return True
            
        except Exception as e:
            self.console.print(f"[red]âŒ åˆ é™¤æ¨¡å‹å¤±è´¥: {e}[/red]")
            return False
    
    def get_model_path(self, model_name: str) -> Optional[str]:
        """è·å–æ¨¡å‹æœ¬åœ°è·¯å¾„"""
        model_config = None
        for config in Config.get_all_models():
            if config['name'] == model_name:
                model_config = config
                break
        
        if not model_config:
            return None
        
        local_path = self.models_dir / model_config['filename']
        return str(local_path) if local_path.exists() else None
    
    def verify_model_integrity(self, model_name: str) -> bool:
        """éªŒè¯æ¨¡å‹å®Œæ•´æ€§"""
        local_path = self.get_model_path(model_name)
        if not local_path or not Path(local_path).exists():
            return False
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆç®€å•éªŒè¯ï¼‰
        file_size = Path(local_path).stat().st_size
        if file_size < 1024 * 1024:  # å°äº1MBå¯èƒ½æœ‰é—®é¢˜
            return False
        
        return True
    
    def get_storage_info(self) -> Dict[str, str]:
        """è·å–å­˜å‚¨ä¿¡æ¯"""
        total_size = 0
        model_count = 0
        
        for model_file in self.models_dir.glob("*.bin"):
            if model_file.is_file():
                total_size += model_file.stat().st_size
                model_count += 1
        
        # è½¬æ¢ä¸ºäººç±»å¯è¯»æ ¼å¼
        def format_size(size_bytes):
            if size_bytes < 1024:
                return f"{size_bytes} B"
            elif size_bytes < 1024**2:
                return f"{size_bytes/1024:.1f} KB"
            elif size_bytes < 1024**3:
                return f"{size_bytes/(1024**2):.1f} MB"
            else:
                return f"{size_bytes/(1024**3):.1f} GB"
        
        return {
            'models_directory': str(self.models_dir),
            'total_models': str(model_count),
            'total_size': format_size(total_size),
            'total_size_bytes': str(total_size)
        }
    
    def cleanup_cache(self):
        """æ¸…ç†ç¼“å­˜æ–‡ä»¶"""
        cache_files = list(self.models_dir.glob("*.tmp")) + list(self.models_dir.glob("*.cache"))
        
        cleaned_count = 0
        for cache_file in cache_files:
            try:
                cache_file.unlink()
                cleaned_count += 1
            except Exception:
                pass
        
        if cleaned_count > 0:
            self.console.print(f"[green]âœ… æ¸…ç†äº† {cleaned_count} ä¸ªç¼“å­˜æ–‡ä»¶[/green]")
        else:
            self.console.print("[yellow]æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ¸…ç†çš„ç¼“å­˜æ–‡ä»¶[/yellow]")

def main():
    """æ¨¡å‹ç®¡ç†å™¨å‘½ä»¤è¡Œç•Œé¢"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Unlimited Agent æ¨¡å‹ç®¡ç†å™¨")
    parser.add_argument("action", choices=["list", "download", "delete", "info", "cleanup"],
                       help="è¦æ‰§è¡Œçš„æ“ä½œ")
    parser.add_argument("--model", type=str, help="æ¨¡å‹åç§°")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶é‡æ–°ä¸‹è½½")
    
    args = parser.parse_args()
    
    manager = ModelManager()
    
    if args.action == "list":
        manager.display_models_table()
    elif args.action == "download":
        if not args.model:
            print("é”™è¯¯: è¯·æŒ‡å®šè¦ä¸‹è½½çš„æ¨¡å‹åç§° (--model)")
            return
        manager.download_model(args.model, args.force)
    elif args.action == "delete":
        if not args.model:
            print("é”™è¯¯: è¯·æŒ‡å®šè¦åˆ é™¤çš„æ¨¡å‹åç§° (--model)")
            return
        manager.delete_model(args.model)
    elif args.action == "info":
        info = manager.get_storage_info()
        console = Console()
        info_panel = Panel(
            f"æ¨¡å‹ç›®å½•: {info['models_directory']}\n"
            f"å·²ä¸‹è½½æ¨¡å‹: {info['total_models']}\n"
            f"æ€»å¤§å°: {info['total_size']}",
            title="ğŸ“Š å­˜å‚¨ä¿¡æ¯",
            border_style="cyan"
        )
        console.print(info_panel)
    elif args.action == "cleanup":
        manager.cleanup_cache()

if __name__ == "__main__":
    main()