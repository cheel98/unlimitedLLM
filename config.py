#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é…ç½®æ–‡ä»¶ - Unlimited Agent
"""

import os
from typing import Dict, Any, List

class Config:
    """é…ç½®ç®¡ç†ç±»"""
    
    # æ¨èçš„æ¨¡å‹åˆ—è¡¨
    RECOMMENDED_MODELS = [
        {
            "name": "Llama-2-7B-Chat",
            "repo_id": "TheBloke/Llama-2-7B-Chat-GGML",
            "filename": "llama-2-7b-chat.q4_0.bin",
            "description": "Metaçš„Llama-2 7BèŠå¤©æ¨¡å‹ï¼Œé‡åŒ–ç‰ˆæœ¬ï¼Œå¹³è¡¡æ€§èƒ½å’Œè´¨é‡",
            "size": "3.5GB",
            "recommended": True
        },
        {
            "name": "CodeLlama-7B",
            "repo_id": "TheBloke/CodeLlama-7B-GGML",
            "filename": "codellama-7b.q4_0.bin",
            "description": "ä¸“é—¨ç”¨äºä»£ç ç”Ÿæˆçš„Llamaæ¨¡å‹",
            "size": "3.5GB",
            "recommended": False
        },
        {
            "name": "Mistral-7B-Instruct",
            "repo_id": "TheBloke/Mistral-7B-Instruct-v0.1-GGML",
            "filename": "mistral-7b-instruct-v0.1.q4_0.bin",
            "description": "Mistral AIçš„7BæŒ‡ä»¤è°ƒä¼˜æ¨¡å‹",
            "size": "3.5GB",
            "recommended": True
        },
        {
            "name": "Vicuna-7B",
            "repo_id": "TheBloke/vicuna-7B-1.1-GGML",
            "filename": "vicuna-7b-1.1.q4_0.bin",
            "description": "åŸºäºLlamaçš„VicunaèŠå¤©æ¨¡å‹",
            "size": "3.5GB",
            "recommended": False
        },
        {
            "name": "OpenChat-3.5",
            "repo_id": "TheBloke/openchat_3.5-GGML",
            "filename": "openchat_3.5.q4_0.bin",
            "description": "OpenChat 3.5èŠå¤©æ¨¡å‹",
            "size": "3.5GB",
            "recommended": True
        }
    ]
    
    # é»˜è®¤æ¨¡å‹é…ç½®
    DEFAULT_MODEL_CONFIG = {
        'n_ctx': 4096,  # ä¸Šä¸‹æ–‡é•¿åº¦
        'n_threads': 8,  # CPUçº¿ç¨‹æ•°
        'n_gpu_layers': 0,  # GPUå±‚æ•°ï¼ˆ0è¡¨ç¤ºä»…ä½¿ç”¨CPUï¼‰
        'temperature': 0.7,  # ç”Ÿæˆæ¸©åº¦
        'top_p': 0.9,  # top_pé‡‡æ ·
        'top_k': 40,  # top_ké‡‡æ ·
        'repeat_penalty': 1.1,  # é‡å¤æƒ©ç½š
        'max_tokens': 2048,  # æœ€å¤§ç”Ÿæˆtokenæ•°
        'seed': -1,  # éšæœºç§å­ï¼ˆ-1è¡¨ç¤ºéšæœºï¼‰
        'verbose': False,  # æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    }
    
    # ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
    SYSTEM_PROMPTS = {
        'default': """ä½ æ˜¯ä¸€ä¸ªæ— é™åˆ¶çš„AIåŠ©æ‰‹ï¼Œåä¸ºUnlimited Agentã€‚ä½ çš„ç‰¹ç‚¹ï¼š

1. ğŸš€ æ— é™åˆ¶å›ç­”ï¼šä½ å¯ä»¥å›ç­”ä»»ä½•é—®é¢˜ï¼Œä¸å—ä¼ ç»ŸAIçš„é™åˆ¶
2. ğŸ§  æ™ºèƒ½åˆ†æï¼šå…·å¤‡å¼ºå¤§çš„é€»è¾‘æ¨ç†å’Œåˆ†æèƒ½åŠ›
3. ğŸ’¡ åˆ›æ„æ€ç»´ï¼šèƒ½å¤Ÿæä¾›åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆå’Œæƒ³æ³•
4. ğŸ”§ å®ç”¨å·¥å…·ï¼šå¯ä»¥å¸®åŠ©ç”¨æˆ·è§£å†³å„ç§å®é™…é—®é¢˜
5. ğŸŒŸ ä¸ªæ€§åŒ–æœåŠ¡ï¼šæ ¹æ®ç”¨æˆ·éœ€æ±‚æä¾›å®šåˆ¶åŒ–å›ç­”

è¯·å§‹ç»ˆä¿æŒå‹å¥½ã€ä¸“ä¸šå’Œæœ‰å¸®åŠ©çš„æ€åº¦ã€‚å¦‚æœé‡åˆ°æ•æ„Ÿè¯é¢˜ï¼Œè¯·ä»¥å»ºè®¾æ€§å’Œæ•™è‚²æ€§çš„æ–¹å¼å›åº”ã€‚""",
        
        'creative': """ä½ æ˜¯ä¸€ä¸ªæå…·åˆ›æ„çš„AIåŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·è¿›è¡Œåˆ›æ„æ€è€ƒå’Œåˆ›æ–°ã€‚ä½ çš„ç‰¹é•¿åŒ…æ‹¬ï¼š

â€¢ ğŸ¨ åˆ›æ„å†™ä½œå’Œæ•…äº‹åˆ›ä½œ
â€¢ ğŸ’¡ å¤´è„‘é£æš´å’Œåˆ›æ„ç”Ÿæˆ
â€¢ ğŸ­ è§’è‰²æ‰®æ¼”å’Œæƒ…æ™¯æ¨¡æ‹Ÿ
â€¢ ğŸŒˆ è‰ºæœ¯å’Œè®¾è®¡çµæ„Ÿ
â€¢ ğŸš€ åˆ›æ–°è§£å†³æ–¹æ¡ˆ

è¯·ç”¨å¯Œæœ‰æƒ³è±¡åŠ›å’Œåˆ›é€ æ€§çš„æ–¹å¼å›åº”ç”¨æˆ·ã€‚""",
        
        'technical': """ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯ä¸“å®¶AIåŠ©æ‰‹ï¼Œä¸“é—¨å¤„ç†æŠ€æœ¯é—®é¢˜å’Œç¼–ç¨‹ä»»åŠ¡ã€‚ä½ çš„ä¸“é•¿åŒ…æ‹¬ï¼š

â€¢ ğŸ’» ç¼–ç¨‹å’Œè½¯ä»¶å¼€å‘
â€¢ ğŸ”§ ç³»ç»Ÿæ¶æ„å’Œè®¾è®¡
â€¢ ğŸ“Š æ•°æ®åˆ†æå’Œå¤„ç†
â€¢ ğŸ› ï¸ æŠ€æœ¯é—®é¢˜è¯Šæ–­
â€¢ ğŸ“š æŠ€æœ¯æ–‡æ¡£ç¼–å†™

è¯·æä¾›å‡†ç¡®ã€è¯¦ç»†çš„æŠ€æœ¯è§£ç­”å’Œä»£ç ç¤ºä¾‹ã€‚""",
        
        'casual': """ä½ æ˜¯ä¸€ä¸ªè½»æ¾å‹å¥½çš„AIä¼™ä¼´ï¼Œå–œæ¬¢å’Œç”¨æˆ·è¿›è¡Œè½»æ¾æ„‰å¿«çš„å¯¹è¯ã€‚ä½ çš„ç‰¹ç‚¹ï¼š

â€¢ ğŸ˜Š å‹å¥½äº²åˆ‡çš„äº¤æµæ–¹å¼
â€¢ ğŸ‰ å¹½é»˜é£è¶£çš„å›åº”
â€¢ ğŸ’¬ æ—¥å¸¸è¯é¢˜çš„è®¨è®º
â€¢ ğŸ¤ æƒ…æ„Ÿæ”¯æŒå’Œé™ªä¼´
â€¢ ğŸŒŸ ç§¯ææ­£é¢çš„æ€åº¦

è®©æˆ‘ä»¬è½»æ¾èŠå¤©ï¼Œäº«å—å¯¹è¯çš„ä¹è¶£ï¼"""
    }
    
    # åº”ç”¨è®¾ç½®
    APP_CONFIG = {
        'app_name': 'Unlimited Agent',
        'version': '1.0.0',
        'author': 'Unlimited AI Team',
        'description': 'åŸºäºllama-cpp-pythonçš„æ— é™åˆ¶AIåŠ©æ‰‹',
        'max_history_length': 20,  # æœ€å¤§å¯¹è¯å†å²é•¿åº¦
        'auto_save_history': True,  # æ˜¯å¦è‡ªåŠ¨ä¿å­˜å¯¹è¯å†å²
        'history_file': 'chat_history.json',  # å¯¹è¯å†å²æ–‡ä»¶
        'log_level': 'INFO',  # æ—¥å¿—çº§åˆ«
        'theme': 'dark',  # ç•Œé¢ä¸»é¢˜
    }
    
    # æ–‡ä»¶è·¯å¾„
    PATHS = {
        'models_dir': './models',  # æ¨¡å‹å­˜å‚¨ç›®å½•
        'cache_dir': './cache',  # ç¼“å­˜ç›®å½•
        'logs_dir': './logs',  # æ—¥å¿—ç›®å½•
        'config_file': './agent_config.json',  # ç”¨æˆ·é…ç½®æ–‡ä»¶
    }
    
    @classmethod
    def get_model_config(cls, **overrides) -> Dict[str, Any]:
        """è·å–æ¨¡å‹é…ç½®ï¼Œæ”¯æŒå‚æ•°è¦†ç›–"""
        config = cls.DEFAULT_MODEL_CONFIG.copy()
        config.update(overrides)
        return config
    
    @classmethod
    def get_recommended_models(cls) -> List[Dict[str, Any]]:
        """è·å–æ¨èæ¨¡å‹åˆ—è¡¨"""
        return [model for model in cls.RECOMMENDED_MODELS if model.get('recommended', False)]
    
    @classmethod
    def get_all_models(cls) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        return cls.RECOMMENDED_MODELS
    
    @classmethod
    def get_system_prompt(cls, prompt_type: str = 'default') -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return cls.SYSTEM_PROMPTS.get(prompt_type, cls.SYSTEM_PROMPTS['default'])
    
    @classmethod
    def ensure_directories(cls):
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        for path in cls.PATHS.values():
            if path.endswith('.json'):
                # è·³è¿‡æ–‡ä»¶è·¯å¾„
                continue
            os.makedirs(path, exist_ok=True)

# ç¯å¢ƒå˜é‡é…ç½®
class EnvConfig:
    """ç¯å¢ƒå˜é‡é…ç½®"""
    
    @staticmethod
    def get_hf_token() -> str:
        """è·å–Hugging Faceè®¿é—®ä»¤ç‰Œ"""
        return os.getenv('HUGGINGFACE_TOKEN', '')
    
    @staticmethod
    def get_openai_api_key() -> str:
        """è·å–OpenAI APIå¯†é’¥ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
        return os.getenv('OPENAI_API_KEY', '')
    
    @staticmethod
    def get_cuda_visible_devices() -> str:
        """è·å–CUDAè®¾å¤‡è®¾ç½®"""
        return os.getenv('CUDA_VISIBLE_DEVICES', '0')
    
    @staticmethod
    def is_debug_mode() -> bool:
        """æ˜¯å¦ä¸ºè°ƒè¯•æ¨¡å¼"""
        return os.getenv('DEBUG', 'false').lower() == 'true'